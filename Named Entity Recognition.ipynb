{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e0821a73-40d3-42de-adf1-1d1e17cb70e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04dbb77c-d28b-4711-87f8-6a65d9ef598b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('learn', 'VB'),\n",
       " ('Part', 'NNP'),\n",
       " ('of', 'IN'),\n",
       " ('Speech', 'NNP'),\n",
       " ('Tagging', 'NNP'),\n",
       " ('using', 'VBG'),\n",
       " ('NLTK', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('spaCy', 'NN'),\n",
       " (',', ','),\n",
       " ('Kamalam', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('being', 'VBG'),\n",
       " ('productive', 'JJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"Trying to learn Part of Speech Tagging using NLTK and spaCy, Kamalam is being productive.\"\n",
    "nltk_pos_tagged = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "nltk_pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e260664-7bda-4120-a903-66aec0b78f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Trying</td>\n",
       "      <td>to</td>\n",
       "      <td>learn</td>\n",
       "      <td>Part</td>\n",
       "      <td>of</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Tagging</td>\n",
       "      <td>using</td>\n",
       "      <td>NLTK</td>\n",
       "      <td>and</td>\n",
       "      <td>spaCy</td>\n",
       "      <td>,</td>\n",
       "      <td>Kamalam</td>\n",
       "      <td>is</td>\n",
       "      <td>being</td>\n",
       "      <td>productive</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>VBG</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>NNP</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>CC</td>\n",
       "      <td>NN</td>\n",
       "      <td>,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBG</td>\n",
       "      <td>JJ</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0   1      2     3   4       5        6      7     8    9   \\\n",
       "Word     Trying  to  learn  Part  of  Speech  Tagging  using  NLTK  and   \n",
       "POS tag     VBG  TO     VB   NNP  IN     NNP      NNP    VBG   NNP   CC   \n",
       "\n",
       "            10 11       12   13     14          15 16  \n",
       "Word     spaCy  ,  Kamalam   is  being  productive  .  \n",
       "POS tag     NN  ,      NNP  VBZ    VBG          JJ  .  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(nltk_pos_tagged, \n",
    "             columns=['Word', 'POS tag']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c7b7f83-272c-4220-903c-7c9202b17489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45fb486f-fdaf-4b77-8548-251ea1d7cec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Trying, 'VBG', 'VERB'),\n",
       " (to, 'TO', 'PART'),\n",
       " (learn, 'VB', 'VERB'),\n",
       " (Part, 'NN', 'NOUN'),\n",
       " (of, 'IN', 'ADP'),\n",
       " (Speech, 'NNP', 'PROPN'),\n",
       " (Tagging, 'NNP', 'PROPN'),\n",
       " (using, 'VBG', 'VERB'),\n",
       " (NLTK, 'NNP', 'PROPN'),\n",
       " (and, 'CC', 'CCONJ'),\n",
       " (spaCy, 'VBN', 'VERB'),\n",
       " (,, ',', 'PUNCT'),\n",
       " (Kamalam, 'NNP', 'PROPN'),\n",
       " (is, 'VBZ', 'AUX'),\n",
       " (being, 'VBG', 'AUX'),\n",
       " (productive, 'JJ', 'ADJ'),\n",
       " (., '.', 'PUNCT')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_sent = nlp(sent)\n",
    "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in spacy_sent]\n",
    "spacy_pos_tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8d0d5dd-1bbb-4683-97f5-30c7a6513b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Trying</td>\n",
       "      <td>to</td>\n",
       "      <td>learn</td>\n",
       "      <td>Part</td>\n",
       "      <td>of</td>\n",
       "      <td>Speech</td>\n",
       "      <td>Tagging</td>\n",
       "      <td>using</td>\n",
       "      <td>NLTK</td>\n",
       "      <td>and</td>\n",
       "      <td>spaCy</td>\n",
       "      <td>,</td>\n",
       "      <td>Kamalam</td>\n",
       "      <td>is</td>\n",
       "      <td>being</td>\n",
       "      <td>productive</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>VBG</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBG</td>\n",
       "      <td>NNP</td>\n",
       "      <td>CC</td>\n",
       "      <td>VBN</td>\n",
       "      <td>,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBG</td>\n",
       "      <td>JJ</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag type</th>\n",
       "      <td>VERB</td>\n",
       "      <td>PART</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>VERB</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>AUX</td>\n",
       "      <td>AUX</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0     1      2     3    4       5        6      7      8   \\\n",
       "Word      Trying    to  learn  Part   of  Speech  Tagging  using   NLTK   \n",
       "POS tag      VBG    TO     VB    NN   IN     NNP      NNP    VBG    NNP   \n",
       "Tag type    VERB  PART   VERB  NOUN  ADP   PROPN    PROPN   VERB  PROPN   \n",
       "\n",
       "             9      10     11       12   13     14          15     16  \n",
       "Word        and  spaCy      ,  Kamalam   is  being  productive      .  \n",
       "POS tag      CC    VBN      ,      NNP  VBZ    VBG          JJ      .  \n",
       "Tag type  CCONJ   VERB  PUNCT    PROPN  AUX    AUX         ADJ  PUNCT  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(spacy_pos_tagged, columns=['Word', 'POS tag', 'Tag type']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7a90888-22e6-4d75-8d2c-71d9784d1228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10900 48\n",
      "(S\n",
      "  Chancellor/NNP\n",
      "  (PP of/IN)\n",
      "  (NP the/DT Exchequer/NNP)\n",
      "  (NP Nigel/NNP Lawson/NNP)\n",
      "  (NP 's/POS restated/VBN commitment/NN)\n",
      "  (PP to/TO)\n",
      "  (NP a/DT firm/NN monetary/JJ policy/NN)\n",
      "  (VP has/VBZ helped/VBN to/TO prevent/VB)\n",
      "  (NP a/DT freefall/NN)\n",
      "  (PP in/IN)\n",
      "  (NP sterling/NN)\n",
      "  (PP over/IN)\n",
      "  (NP the/DT past/JJ week/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "#Chunking\n",
    "from nltk.corpus import conll2000\n",
    "data = conll2000.chunked_sents()\n",
    "train_data = data[:10900]\n",
    "test_data = data[10900:] \n",
    "\n",
    "print(len(train_data), len(test_data))\n",
    "print(train_data[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a492e69-d11a-45d4-872c-988f0a962b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chancellor', 'NNP', 'O'),\n",
       " ('of', 'IN', 'B-PP'),\n",
       " ('the', 'DT', 'B-NP'),\n",
       " ('Exchequer', 'NNP', 'I-NP'),\n",
       " ('Nigel', 'NNP', 'B-NP'),\n",
       " ('Lawson', 'NNP', 'I-NP'),\n",
       " (\"'s\", 'POS', 'B-NP'),\n",
       " ('restated', 'VBN', 'I-NP'),\n",
       " ('commitment', 'NN', 'I-NP'),\n",
       " ('to', 'TO', 'B-PP'),\n",
       " ('a', 'DT', 'B-NP'),\n",
       " ('firm', 'NN', 'I-NP'),\n",
       " ('monetary', 'JJ', 'I-NP'),\n",
       " ('policy', 'NN', 'I-NP'),\n",
       " ('has', 'VBZ', 'B-VP'),\n",
       " ('helped', 'VBN', 'I-VP'),\n",
       " ('to', 'TO', 'I-VP'),\n",
       " ('prevent', 'VB', 'I-VP'),\n",
       " ('a', 'DT', 'B-NP'),\n",
       " ('freefall', 'NN', 'I-NP'),\n",
       " ('in', 'IN', 'B-PP'),\n",
       " ('sterling', 'NN', 'B-NP'),\n",
       " ('over', 'IN', 'B-PP'),\n",
       " ('the', 'DT', 'B-NP'),\n",
       " ('past', 'JJ', 'I-NP'),\n",
       " ('week', 'NN', 'I-NP'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.chunk.util import tree2conlltags, conlltags2tree\n",
    "wtc = tree2conlltags(train_data[1])\n",
    "wtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bc5fbbd-d1ba-4e72-8415-df263593f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conll_tag_chunks(chunk_sents):\n",
    "    tagged_sents = [tree2conlltags(tree) for tree in chunk_sents]\n",
    "    return [[(t, c) for (w, t, c) in sent] for sent in tagged_sents]\n",
    "    \n",
    "def combined_tagger(train_data, taggers, backoff=None):\n",
    "    for tagger in taggers:\n",
    "        backoff = tagger(train_data, backoff=backoff)\n",
    "    return backoff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f78184ac-477f-42ac-aec0-586804dad478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger, BigramTagger\n",
    "from nltk.chunk import ChunkParserI #abstract class, can be used to implement as wanted\n",
    "\n",
    "# define the chunker class\n",
    "class NGramTagChunker(ChunkParserI):\n",
    "    def __init__(self, train_sentences, tagger_classes=[UnigramTagger, BigramTagger]):\n",
    "        train_sent_tags = conll_tag_chunks(train_sentences)\n",
    "        self.chunk_tagger = combined_tagger(train_sent_tags, tagger_classes)\n",
    "\n",
    "    def parse(self, tagged_sentence):\n",
    "        if not tagged_sentence: \n",
    "            return None\n",
    "        pos_tags = [tag for word, tag in tagged_sentence]\n",
    "        chunk_pos_tags = self.chunk_tagger.tag(pos_tags)\n",
    "        chunk_tags = [chunk_tag for (pos_tag, chunk_tag) in chunk_pos_tags]\n",
    "        wpc_tags = [(word, pos_tag, chunk_tag) for ((word, pos_tag), chunk_tag) in zip(tagged_sentence, chunk_tags)]\n",
    "        return conlltags2tree(wpc_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26040aee-3fa0-449a-9e39-07bd02179cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkParse score:\n",
      "    IOB Accuracy:  90.0%%\n",
      "    Precision:     82.1%%\n",
      "    Recall:        86.3%%\n",
      "    F-Measure:     84.1%%\n"
     ]
    }
   ],
   "source": [
    "# train chunker model  \n",
    "ntc = NGramTagChunker(train_data)\n",
    "# evaluate chunker model performance\n",
    "print(ntc.accuracy(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "724fb144-8292-45a4-b0b2-d1f5e3af5b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Testing the chunker model, hopefully the result comes out well. Kamalam would be happy then to go for lunch.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Testing the chunker model, hopefully the result comes out well. Kamalam would be happy then to go for lunch.'\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c271447d-3b74-483d-99f9-c4b0a81a9644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (VP Testing/VBG)\n",
      "  (NP the/DT chunker/NN model/NN)\n",
      "  ,/,\n",
      "  hopefully/RB\n",
      "  (NP the/DT result/NN)\n",
      "  (VP comes/VBZ)\n",
      "  out/RP\n",
      "  well/RB\n",
      "  ./.\n",
      "  (NP Kamalam/NNP)\n",
      "  (VP would/MD be/VB)\n",
      "  (NP happy/JJ)\n",
      "  then/RB\n",
      "  (VP to/TO go/VB)\n",
      "  (PP for/IN)\n",
      "  (NP lunch/NN)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "nltk_pos_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "chunk_tree = ntc.parse(nltk_pos_tagged)\n",
    "print(chunk_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a4851386-b99a-4a71-81dd-2c209bd6d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Couldn't install ghostscripts/standford nlp parser for viewing the hierarchy in the chunks, but that could be done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2295b1fa-ce19-474f-a978-dc34e13479dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"bc87a9fdc552496682e38e52ec836717-0\" class=\"displacy\" width=\"1700\" height=\"467.0\" direction=\"ltr\" style=\"max-width: none; height: 467.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Trying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">learn</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">Part</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">Speech</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">Tagging</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">using</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">NLTK</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">and</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">spaCy,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">Kamalam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1480\">being</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1480\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"377.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">productive.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-0\" stroke-width=\"2px\" d=\"M70,332.0 C70,2.0 1480.0,2.0 1480.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,334.0 L64,324.0 76,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-1\" stroke-width=\"2px\" d=\"M180,332.0 C180,277.0 245.0,277.0 245.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,334.0 L174,324.0 186,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-2\" stroke-width=\"2px\" d=\"M70,332.0 C70,222.0 250.0,222.0 250.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250.0,334.0 L256.0,324.0 244.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-3\" stroke-width=\"2px\" d=\"M290,332.0 C290,277.0 355.0,277.0 355.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M355.0,334.0 L361.0,324.0 349.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-4\" stroke-width=\"2px\" d=\"M400,332.0 C400,277.0 465.0,277.0 465.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M465.0,334.0 L471.0,324.0 459.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-5\" stroke-width=\"2px\" d=\"M620,332.0 C620,277.0 685.0,277.0 685.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,334.0 L614,324.0 626,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-6\" stroke-width=\"2px\" d=\"M510,332.0 C510,222.0 690.0,222.0 690.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M690.0,334.0 L696.0,324.0 684.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-7\" stroke-width=\"2px\" d=\"M290,332.0 C290,167.0 805.0,167.0 805.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M805.0,334.0 L811.0,324.0 799.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-8\" stroke-width=\"2px\" d=\"M840,332.0 C840,277.0 905.0,277.0 905.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M905.0,334.0 L911.0,324.0 899.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-9\" stroke-width=\"2px\" d=\"M290,332.0 C290,112.0 1030.0,112.0 1030.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030.0,334.0 L1036.0,324.0 1024.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-10\" stroke-width=\"2px\" d=\"M290,332.0 C290,57.0 1145.0,57.0 1145.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1145.0,334.0 L1151.0,324.0 1139.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-11\" stroke-width=\"2px\" d=\"M1280,332.0 C1280,222.0 1460.0,222.0 1460.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1280,334.0 L1274,324.0 1286,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-12\" stroke-width=\"2px\" d=\"M1390,332.0 C1390,277.0 1455.0,277.0 1455.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1390,334.0 L1384,324.0 1396,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-bc87a9fdc552496682e38e52ec836717-0-13\" stroke-width=\"2px\" d=\"M1500,332.0 C1500,277.0 1565.0,277.0 1565.0,332.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-bc87a9fdc552496682e38e52ec836717-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1565.0,334.0 L1571.0,324.0 1559.0,324.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(spacy_sent, jupyter=True, \n",
    "                options={'distance': 110,\n",
    "                         'arrow_stroke': 2,\n",
    "                         'arrow_width': 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3b8adfa3-0d53-42ae-8bca-d078de82cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER using spacy [Can also be done with nltk using StanfordNERtagger, but need to download it in the system and then use it along with nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "329df4a0-f1c3-4bb7-be9e-ee1a7316969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Three more countries have joined an “international grand committee” of parliaments, adding to calls for Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within Facebook.”'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f8aa344-59f7-4264-a439-2d4c15188142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Three more countries have joined an “international grand committee” of parliaments, adding to calls for Facebook’s boss, Mark Zuckerberg, to give evidence on misinformation to the coalition. Brazil, Latvia and Singapore bring the total to eight different parliaments across the world, with plans to send representatives to London on 27 November with the intention of hearing from Zuckerberg. Since the Cambridge Analytica scandal broke, the Facebook chief has only appeared in front of two legislatures: the American Senate and House of Representatives, and the European parliament. Facebook has consistently rebuffed attempts from others, including the UK and Canadian parliaments, to hear from Zuckerberg. He added that an article in the New York Times on Thursday, in which the paper alleged a pattern of behaviour from Facebook to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within Facebook.”"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_review = nlp(sentence)\n",
    "spacy_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b0f4bde-e15a-49d2-acd1-823cd529c8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Three', 'CARDINAL'), ('more', ''), ('countries', ''), ('have', ''), ('joined', ''), ('an', ''), ('“', ''), ('international', ''), ('grand', ''), ('committee', ''), ('”', ''), ('of', ''), ('parliaments', ''), (',', ''), ('adding', ''), ('to', ''), ('calls', ''), ('for', ''), ('Facebook', 'ORG'), ('’s', ''), ('boss', ''), (',', ''), ('Mark', 'PERSON'), ('Zuckerberg', 'PERSON'), (',', ''), ('to', ''), ('give', ''), ('evidence', ''), ('on', ''), ('misinformation', ''), ('to', ''), ('the', ''), ('coalition', ''), ('.', ''), ('Brazil', 'GPE'), (',', ''), ('Latvia', 'GPE'), ('and', ''), ('Singapore', 'GPE'), ('bring', ''), ('the', ''), ('total', ''), ('to', ''), ('eight', 'CARDINAL'), ('different', ''), ('parliaments', ''), ('across', ''), ('the', ''), ('world', ''), (',', ''), ('with', ''), ('plans', ''), ('to', ''), ('send', ''), ('representatives', ''), ('to', ''), ('London', 'GPE'), ('on', ''), ('27', 'DATE'), ('November', 'DATE'), ('with', ''), ('the', ''), ('intention', ''), ('of', ''), ('hearing', ''), ('from', ''), ('Zuckerberg', 'PERSON'), ('.', ''), ('Since', ''), ('the', ''), ('Cambridge', 'GPE'), ('Analytica', 'GPE'), ('scandal', ''), ('broke', ''), (',', ''), ('the', ''), ('Facebook', 'ORG'), ('chief', ''), ('has', ''), ('only', ''), ('appeared', ''), ('in', ''), ('front', ''), ('of', ''), ('two', 'CARDINAL'), ('legislatures', ''), (':', ''), ('the', ''), ('American', 'NORP'), ('Senate', 'ORG'), ('and', ''), ('House', 'ORG'), ('of', 'ORG'), ('Representatives', 'ORG'), (',', ''), ('and', ''), ('the', ''), ('European', 'NORP'), ('parliament', ''), ('.', ''), ('Facebook', ''), ('has', ''), ('consistently', ''), ('rebuffed', ''), ('attempts', ''), ('from', ''), ('others', ''), (',', ''), ('including', ''), ('the', ''), ('UK', 'GPE'), ('and', ''), ('Canadian', 'NORP'), ('parliaments', ''), (',', ''), ('to', ''), ('hear', ''), ('from', ''), ('Zuckerberg', 'PERSON'), ('.', ''), ('He', ''), ('added', ''), ('that', ''), ('an', ''), ('article', ''), ('in', ''), ('the', 'ORG'), ('New', 'ORG'), ('York', 'ORG'), ('Times', 'ORG'), ('on', ''), ('Thursday', 'DATE'), (',', ''), ('in', ''), ('which', ''), ('the', ''), ('paper', ''), ('alleged', ''), ('a', ''), ('pattern', ''), ('of', ''), ('behaviour', ''), ('from', ''), ('Facebook', ''), ('to', ''), ('“', ''), ('delay', ''), (',', ''), ('deny', ''), ('and', ''), ('deflect', ''), ('”', ''), ('negative', ''), ('news', ''), ('stories', ''), (',', ''), ('“', ''), ('raises', ''), ('further', ''), ('questions', ''), ('about', ''), ('how', ''), ('recent', ''), ('data', ''), ('breaches', ''), ('were', ''), ('allegedly', ''), ('dealt', ''), ('with', ''), ('within', ''), ('Facebook', 'PERSON'), ('.', ''), ('”', '')]\n"
     ]
    }
   ],
   "source": [
    "ner_tagged = [(word.text, word.ent_type_) for word in spacy_review]\n",
    "print(ner_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "45bebacb-ae5a-4c56-8e3e-9922bd0522f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " more countries have joined an “international grand committee” of parliaments, adding to calls for \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "’s boss, \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Mark Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", to give evidence on misinformation to the coalition. \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brazil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Latvia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Singapore\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " bring the total to \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    eight\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " different parliaments across the world, with plans to send representatives to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    London\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    27 November\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " with the intention of hearing from \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". Since the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Cambridge Analytica\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " scandal broke, the \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " chief has only appeared in front of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    two\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " legislatures: the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    American\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Senate\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    House of Representatives\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " parliament. Facebook has consistently rebuffed attempts from others, including the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    UK\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Canadian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " parliaments, to hear from \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Zuckerberg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". He added that an article in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the New York Times\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Thursday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", in which the paper alleged a pattern of behaviour from Facebook to “delay, deny and deflect” negative news stories, “raises further questions about how recent data breaches were allegedly dealt with within \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ".”</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize named entities\n",
    "displacy.render(spacy_review, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df6ba6f2-156a-4a23-8897-b0787c822f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "temp_entity_name = ''\n",
    "temp_named_entity = None\n",
    "for term, tag in ner_tagged:\n",
    "    if tag:\n",
    "        temp_entity_name = ' '.join([temp_entity_name, term]).strip()\n",
    "        temp_named_entity = (temp_entity_name, tag)\n",
    "    else:\n",
    "        if temp_named_entity:\n",
    "            named_entities.append(temp_named_entity)\n",
    "            temp_entity_name = ''\n",
    "            temp_named_entity = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9f4d20a-d7de-4a87-97b0-fbeacee3f371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Three', 'CARDINAL'),\n",
       " ('Facebook', 'ORG'),\n",
       " ('Mark Zuckerberg', 'PERSON'),\n",
       " ('Brazil', 'GPE'),\n",
       " ('Latvia', 'GPE'),\n",
       " ('Singapore', 'GPE'),\n",
       " ('eight', 'CARDINAL'),\n",
       " ('London', 'GPE'),\n",
       " ('27 November', 'DATE'),\n",
       " ('Zuckerberg', 'PERSON'),\n",
       " ('Cambridge Analytica', 'GPE'),\n",
       " ('Facebook', 'ORG'),\n",
       " ('two', 'CARDINAL'),\n",
       " ('American Senate', 'ORG'),\n",
       " ('House of Representatives', 'ORG'),\n",
       " ('European', 'NORP'),\n",
       " ('UK', 'GPE'),\n",
       " ('Canadian', 'NORP'),\n",
       " ('Zuckerberg', 'PERSON'),\n",
       " ('the New York Times', 'ORG'),\n",
       " ('Thursday', 'DATE'),\n",
       " ('Facebook', 'PERSON')]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99b028cb-4c16-497c-ab27-5c94f82927b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('GPE', 6),\n",
       " ('ORG', 5),\n",
       " ('PERSON', 4),\n",
       " ('CARDINAL', 3),\n",
       " ('DATE', 2),\n",
       " ('NORP', 2)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter([item[1] for item in named_entities])\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "009f5ae4-1e2e-46a2-8b3b-f93ec670d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweaking available POS Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b8b083cb-f411-4fb2-aead-a2344806e2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Since the Cambridge Analytica scandal broke, Mark Zuckerberg has only appeared in front of two legislatures.'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Since the Cambridge Analytica scandal broke, Mark Zuckerberg has only appeared in front of two legislatures.\"\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a212c20-5962-4012-a63c-5aca85108047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Since</td>\n",
       "      <td>the</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Analytica</td>\n",
       "      <td>scandal</td>\n",
       "      <td>broke</td>\n",
       "      <td>,</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>has</td>\n",
       "      <td>only</td>\n",
       "      <td>appeared</td>\n",
       "      <td>in</td>\n",
       "      <td>front</td>\n",
       "      <td>of</td>\n",
       "      <td>two</td>\n",
       "      <td>legislatures</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>IN</td>\n",
       "      <td>DT</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>,</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>RB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NN</td>\n",
       "      <td>IN</td>\n",
       "      <td>CD</td>\n",
       "      <td>NNS</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1          2          3        4      5  6     7   \\\n",
       "Word     Since  the  Cambridge  Analytica  scandal  broke  ,  Mark   \n",
       "POS tag     IN   DT        NNP        NNP       NN    VBD  ,   NNP   \n",
       "\n",
       "                 8    9     10        11  12     13  14   15            16 17  \n",
       "Word     Zuckerberg  has  only  appeared  in  front  of  two  legislatures  .  \n",
       "POS tag         NNP  VBZ    RB       VBN  IN     NN  IN   CD           NNS  .  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = nltk.word_tokenize(sentence)\n",
    "nltk_pos_tagged = nltk.pos_tag(sentence_tokens)\n",
    "pd.DataFrame(nltk_pos_tagged, columns=['Word', 'POS tag']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "514d0dc7-507d-4255-ab7f-f317da02e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3500, 414)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import treebank\n",
    "data = treebank.tagged_sents()\n",
    "train_data = data[:3500]\n",
    "test_data = data[3500:]\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "58ea0727-1c68-45c2-aaf6-739d0f014d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a5b11c39-5f7b-4f08-9833-8ed34abb0078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IN'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = [tag for (word, tag) in treebank.tagged_words(\"wsj_0003.mrg\")]\n",
    "nltk.FreqDist(tags).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7e5b9755-a2d0-4e14-a77f-894324ceed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1454158195372253"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default tagger\n",
    "from nltk.tag import DefaultTagger #Tags every word with the same mentioned POS\n",
    "dt = DefaultTagger('NN')\n",
    "dt.accuracy(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "67a4e2f8-50a3-4f79-bb99-651c66dcab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Since</td>\n",
       "      <td>the</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Analytica</td>\n",
       "      <td>scandal</td>\n",
       "      <td>broke</td>\n",
       "      <td>,</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>has</td>\n",
       "      <td>only</td>\n",
       "      <td>appeared</td>\n",
       "      <td>in</td>\n",
       "      <td>front</td>\n",
       "      <td>of</td>\n",
       "      <td>two</td>\n",
       "      <td>legislatures</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1          2          3        4      5   6     7   \\\n",
       "Word     Since  the  Cambridge  Analytica  scandal  broke   ,  Mark   \n",
       "POS tag     NN   NN         NN         NN       NN     NN  NN    NN   \n",
       "\n",
       "                 8    9     10        11  12     13  14   15            16  17  \n",
       "Word     Zuckerberg  has  only  appeared  in  front  of  two  legislatures   .  \n",
       "POS tag          NN   NN    NN        NN  NN     NN  NN   NN            NN  NN  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagged = dt.tag(nltk.word_tokenize(sentence))\n",
    "pd.DataFrame(pos_tagged, columns=['Word', 'POS tag']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32effe38-6008-4242-9163-6dd7b39e5f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Regexp Tagger: size=8>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex tagger\n",
    "from nltk.tag import RegexpTagger\n",
    "# define regex tag patterns\n",
    "patterns = [\n",
    "        (r'.*ing$', 'VBG'),               # gerunds\n",
    "        (r'.*ed$', 'VBD'),                # simple past\n",
    "        (r'.*es$', 'VBZ'),                # 3rd singular present\n",
    "        (r'.*ould$', 'MD'),               # modals\n",
    "        (r'.*\\'s$', 'NN$'),               # possessive nouns\n",
    "        (r'.*s$', 'NNS'),                 # plural nouns\n",
    "        (r'^-?[0-9]+(.[0-9]+)?$', 'CD'),  # cardinal numbers\n",
    "        (r'.*', 'NN')                     # nouns \n",
    "]\n",
    "rt = RegexpTagger(patterns)\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "13a3e56b-cfee-4556-b76d-f68b139a110e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24039113176493368"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.accuracy(test_data) #all accuracies are based on the accepted gold standard test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ea9b1a3-0330-4aad-9230-5b18408555c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Since</td>\n",
       "      <td>the</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>Analytica</td>\n",
       "      <td>scandal</td>\n",
       "      <td>broke</td>\n",
       "      <td>,</td>\n",
       "      <td>Mark</td>\n",
       "      <td>Zuckerberg</td>\n",
       "      <td>has</td>\n",
       "      <td>only</td>\n",
       "      <td>appeared</td>\n",
       "      <td>in</td>\n",
       "      <td>front</td>\n",
       "      <td>of</td>\n",
       "      <td>two</td>\n",
       "      <td>legislatures</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS tag</th>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBD</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1          2          3        4      5   6     7   \\\n",
       "Word     Since  the  Cambridge  Analytica  scandal  broke   ,  Mark   \n",
       "POS tag     NN   NN         NN         NN       NN     NN  NN    NN   \n",
       "\n",
       "                 8    9     10        11  12     13  14   15            16  17  \n",
       "Word     Zuckerberg  has  only  appeared  in  front  of  two  legislatures   .  \n",
       "POS tag          NN  NNS    NN       VBD  NN     NN  NN   NN           VBZ  NN  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagged = rt.tag(nltk.word_tokenize(sentence))\n",
    "pd.DataFrame(pos_tagged, columns=['Word', 'POS tag']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b8e795fd-445a-4839-8d83-6cef81baf3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3862489570503397"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lookup Taggers (Unigram Tagger)\n",
    "#Most likely tag from the most frequent words are stored in a lookup table\n",
    "fd = nltk.FreqDist(treebank.words(\"wsj_0003.mrg\"))\n",
    "cfd = nltk.ConditionalFreqDist(treebank.tagged_words(\"wsj_0003.mrg\"))\n",
    "most_freq_words = fd.most_common(100)\n",
    "\n",
    "#finding the most likely tags\n",
    "likely_tags = dict((word, cfd[word].max()) for (word, num) in most_freq_words)\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags)\n",
    "baseline_tagger.accuracy(treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7f6cf875-ee72-4378-949f-0050258c9387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('form', None),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " ('once', 'RB'),\n",
       " ('used', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarette', 'NN'),\n",
       " ('filters', 'NNS'),\n",
       " ('has', 'VBZ'),\n",
       " ('caused', None),\n",
       " ('a', 'DT'),\n",
       " ('high', None),\n",
       " ('percentage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('cancer', 'NN'),\n",
       " ('deaths', 'NNS'),\n",
       " ('among', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('group', None),\n",
       " ('of', 'IN'),\n",
       " ('workers', 'NNS'),\n",
       " ('exposed', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('it', 'PRP'),\n",
       " ('more', 'RBR'),\n",
       " ('than', 'IN'),\n",
       " ('30', None),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " (',', ','),\n",
       " ('researchers', 'NNS'),\n",
       " ('reported', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = treebank.sents(\"wsj_0003.mrg\")\n",
    "baseline_tagger.tag(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "690b3366-1f55-47ed-becf-e9d4f4707b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 'DT'),\n",
       " ('form', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('asbestos', 'NN'),\n",
       " ('once', 'RB'),\n",
       " ('used', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('make', 'VB'),\n",
       " ('Kent', 'NNP'),\n",
       " ('cigarette', 'NN'),\n",
       " ('filters', 'NNS'),\n",
       " ('has', 'VBZ'),\n",
       " ('caused', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('high', 'NN'),\n",
       " ('percentage', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('cancer', 'NN'),\n",
       " ('deaths', 'NNS'),\n",
       " ('among', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('group', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('workers', 'NNS'),\n",
       " ('exposed', 'VBN'),\n",
       " ('*', '-NONE-'),\n",
       " ('to', 'TO'),\n",
       " ('it', 'PRP'),\n",
       " ('more', 'RBR'),\n",
       " ('than', 'IN'),\n",
       " ('30', 'NN'),\n",
       " ('years', 'NNS'),\n",
       " ('ago', 'IN'),\n",
       " (',', ','),\n",
       " ('researchers', 'NNS'),\n",
       " ('reported', 'VBD'),\n",
       " ('0', '-NONE-'),\n",
       " ('*T*-1', '-NONE-'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#backoff is nothing but when most of the words, don't have a tag, it's assigned None, when with backoff mentioned, the backup method is used.\n",
    "baseline_tagger = nltk.UnigramTagger(model=likely_tags, backoff=nltk.DefaultTagger('NN')) #In this case \"NN\" is assigned when it can't find any corresponding word to assign a tag.\n",
    "baseline_tagger.tag(sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48d30079-72b2-4e39-9f3a-e59f870bb68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TrigramTagger: size=41616>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## N gram taggers\n",
    "from nltk.tag import UnigramTagger\n",
    "from nltk.tag import BigramTagger\n",
    "from nltk.tag import TrigramTagger\n",
    "\n",
    "ut = UnigramTagger(train_data)\n",
    "bt = BigramTagger(train_data)\n",
    "tt = TrigramTagger(train_data)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "39136ebd-a21b-4b2a-a2a1-3c273ca7c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance:\n",
      "UnigramTagger: 0.8607803272340013\n",
      "BigramTagger: 0.13466937748087907\n",
      "TrigramTagger: 0.08064672281924679\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance:\\nUnigramTagger: {}\\nBigramTagger: {}\\nTrigramTagger: {}\".format(ut.accuracy(test_data), bt.accuracy(test_data), tt.accuracy(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "57db0aa0-3dc5-40a0-83e1-658b7e0b77ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8701713621841417"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = nltk.BigramTagger(train_data, backoff=ut)\n",
    "t.accuracy(test_data) #Comparitively the combined tagger works well because of backoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f008741c-f504-412d-89ab-b9de179ab1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = UnigramTagger(train_data, backoff=nltk.DefaultTagger('NN'))\n",
    "t2 = BigramTagger(train_data, backoff=t1)\n",
    "t3 = TrigramTagger(train_data, backoff=t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8297aa3a-00a0-4e4b-9801-970c5641dd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8874043953916159"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3.accuracy(test_data) #Even better results when defined backing down from trigram to default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9a98482a-c95d-4f83-969b-3020c9728b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Supervised Learning for POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "efc9e692-56e7-4942-bba4-05125f0c863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ClassifierBasedTagger: <nltk.classify.naivebayes.NaiveBayesClassifier object at 0x000001B7471FE750>>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.tag.sequential import ClassifierBasedPOSTagger\n",
    "nbt = ClassifierBasedPOSTagger(train=train_data, classifier_builder=NaiveBayesClassifier.train)\n",
    "nbt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "a144bf51-e76d-467f-944b-b91526f6368c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306806079969019"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbt.accuracy(test_data) #better results than NGram Taggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e50f112e-3d3c-4149-9e54-ea692665899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customising NER\n",
    "#NER - Sequence modelling problem\n",
    "#Trying out CRF --> Conditional Random Fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f317e273-2011-4319-b230-574e955181d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1048575 entries, 0 to 1048574\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count    Dtype \n",
      "---  ------      --------------    ----- \n",
      " 0   Sentence #  47959 non-null    object\n",
      " 1   Word        1048565 non-null  object\n",
      " 2   POS         1048575 non-null  object\n",
      " 3   Tag         1048575 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 32.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kamalam.s\\Desktop\\kamalam's\\nlp dev\\data\\ner\\ner_dataset.csv\", encoding='ISO-8859-1')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "969faa2c-0cb0-4397-9f01-0610880dbdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048565</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>impact</td>\n",
       "      <td>.</td>\n",
       "      <td>Indian</td>\n",
       "      <td>forces</td>\n",
       "      <td>said</td>\n",
       "      <td>they</td>\n",
       "      <td>responded</td>\n",
       "      <td>to</td>\n",
       "      <td>the</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBP</td>\n",
       "      <td>VBN</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>TO</td>\n",
       "      <td>VB</td>\n",
       "      <td>DT</td>\n",
       "      <td>...</td>\n",
       "      <td>NN</td>\n",
       "      <td>.</td>\n",
       "      <td>JJ</td>\n",
       "      <td>NNS</td>\n",
       "      <td>VBD</td>\n",
       "      <td>PRP</td>\n",
       "      <td>VBD</td>\n",
       "      <td>TO</td>\n",
       "      <td>DT</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-geo</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-gpe</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 1048575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0       1              2       3        4        5        \\\n",
       "Sentence #  Sentence: 1     NaN            NaN     NaN      NaN      NaN   \n",
       "Word          Thousands      of  demonstrators    have  marched  through   \n",
       "POS                 NNS      IN            NNS     VBP      VBN       IN   \n",
       "Tag                   O       O              O       O        O        O   \n",
       "\n",
       "           6       7        8       9        ... 1048565 1048566  \\\n",
       "Sentence #     NaN     NaN      NaN     NaN  ...     NaN     NaN   \n",
       "Word        London      to  protest     the  ...  impact       .   \n",
       "POS            NNP      TO       VB      DT  ...      NN       .   \n",
       "Tag          B-geo       O        O       O  ...       O       O   \n",
       "\n",
       "                    1048567 1048568 1048569 1048570    1048571 1048572  \\\n",
       "Sentence #  Sentence: 47959     NaN     NaN     NaN        NaN     NaN   \n",
       "Word                 Indian  forces    said    they  responded      to   \n",
       "POS                      JJ     NNS     VBD     PRP        VBD      TO   \n",
       "Tag                   B-gpe       O       O       O          O       O   \n",
       "\n",
       "           1048573 1048574  \n",
       "Sentence #     NaN     NaN  \n",
       "Word           the  attack  \n",
       "POS             DT      NN  \n",
       "Tag              O       O  \n",
       "\n",
       "[4 rows x 1048575 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "149e24db-b502-434d-998b-65f6fd8ab4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 35177, 42, 17)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentence #'].nunique(), df.Word.nunique(), df.POS.nunique(), df.Tag.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1308b320-ed2c-43b7-bb91-5eb106702446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geo = Geographical Entity\n",
    "# org = Organization\n",
    "# per = Person\n",
    "# gpe = Geopolitical Entity\n",
    "# tim = Time indicator\n",
    "# art = Artifact\n",
    "# eve = Event\n",
    "# nat = Natural Phenomenon\n",
    "# Anything other than the above has been tagged O\n",
    "# IOB is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d7fa966c-92e0-4c08-bf19-638b184c7262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "O        887908\n",
       "B-geo     37644\n",
       "B-tim     20333\n",
       "B-org     20143\n",
       "I-per     17251\n",
       "B-per     16990\n",
       "I-org     16784\n",
       "B-gpe     15870\n",
       "I-geo      7414\n",
       "I-tim      6528\n",
       "B-art       402\n",
       "B-eve       308\n",
       "I-art       297\n",
       "I-eve       253\n",
       "B-nat       201\n",
       "I-gpe       198\n",
       "I-nat        51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Tag.value_counts()\n",
    "#It can be seen that, the distribution of values in different tags is unbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "35d2b490-a616-4c0c-9904-690a5671e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = str(sent[i][0])\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "429aeacd-7ddb-4ebc-89f3-7581bcbd0106",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, p, t) for w, p, t in zip(s['Word'].values.tolist(), \n",
    "                                                   s['POS'].values.tolist(), \n",
    "                                                   s['Tag'].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "66c0ec22-3e43-4d2d-a9c2-303f79e38606",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('Sentence #').apply(agg_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "409bf214-f360-47d9-a7ca-a2d35bf479fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([('Thousands', 'NNS', 'O')])]\n"
     ]
    }
   ],
   "source": [
    "print(grouped_df[grouped_df.index == 'Sentence: 1'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "e34c3f7a-7d8c-4edf-bba5-6b67d9e75175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O')]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [s for s in grouped_df]\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "601b2624-a307-4ef7-a943-9cfb7760a08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35969, 1), (11990, 1))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([sent2features(s) for s in sentences])\n",
    "y = np.array([sent2labels(s) for s in sentences])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "311cbeec-1126-4b81-abe2-0a692953b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_crfsuite\n",
    "crf = sklearn_crfsuite.CRF(c1=0.1,\n",
    "                           c2=0.1,\n",
    "                           max_iterations=100,\n",
    "                           all_possible_transitions=True,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2dc96b6b-b31f-4103-835b-c888e59325e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████████████████████████████████| 35969/35969 [00:00<00:00, 78037.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 6894\n",
      "Seconds required: 0.051\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=0.06  loss=42206.99 active=6796  feature_norm=1.00\n",
      "Iter 2   time=0.03  loss=34905.36 active=6538  feature_norm=1.62\n",
      "Iter 3   time=0.02  loss=30297.87 active=6681  feature_norm=1.92\n",
      "Iter 4   time=0.02  loss=21137.73 active=6638  feature_norm=3.81\n",
      "Iter 5   time=0.03  loss=18360.41 active=6699  feature_norm=4.48\n",
      "Iter 6   time=0.04  loss=16672.71 active=6720  feature_norm=5.32\n",
      "Iter 7   time=0.03  loss=15431.20 active=6736  feature_norm=6.37\n",
      "Iter 8   time=0.03  loss=14549.78 active=6750  feature_norm=7.62\n",
      "Iter 9   time=0.04  loss=13560.74 active=6735  feature_norm=8.80\n",
      "Iter 10  time=0.04  loss=12775.76 active=6741  feature_norm=10.12\n",
      "Iter 11  time=0.03  loss=12078.85 active=6715  feature_norm=11.93\n",
      "Iter 12  time=0.03  loss=11608.40 active=6725  feature_norm=13.26\n",
      "Iter 13  time=0.03  loss=10997.08 active=6642  feature_norm=15.96\n",
      "Iter 14  time=0.03  loss=10425.79 active=6375  feature_norm=18.21\n",
      "Iter 15  time=0.03  loss=9982.92  active=6277  feature_norm=20.33\n",
      "Iter 16  time=0.03  loss=9406.81  active=6006  feature_norm=24.60\n",
      "Iter 17  time=0.03  loss=9101.83  active=6010  feature_norm=27.29\n",
      "Iter 18  time=0.03  loss=8877.01  active=6077  feature_norm=28.11\n",
      "Iter 19  time=0.03  loss=8688.75  active=6110  feature_norm=29.21\n",
      "Iter 20  time=0.04  loss=8351.36  active=6105  feature_norm=31.56\n",
      "Iter 21  time=0.03  loss=8114.99  active=6073  feature_norm=34.30\n",
      "Iter 22  time=0.03  loss=7879.94  active=6042  feature_norm=36.97\n",
      "Iter 23  time=0.02  loss=7551.98  active=6004  feature_norm=42.63\n",
      "Iter 24  time=0.02  loss=7318.96  active=5913  feature_norm=47.65\n",
      "Iter 25  time=0.03  loss=7048.74  active=5949  feature_norm=51.76\n",
      "Iter 26  time=0.02  loss=6854.21  active=5948  feature_norm=55.95\n",
      "Iter 27  time=0.03  loss=6611.27  active=5926  feature_norm=63.05\n",
      "Iter 28  time=0.03  loss=6507.89  active=5927  feature_norm=66.98\n",
      "Iter 29  time=0.04  loss=6392.87  active=5930  feature_norm=70.41\n",
      "Iter 30  time=0.03  loss=6311.71  active=5887  feature_norm=73.49\n",
      "Iter 31  time=0.03  loss=6252.88  active=5866  feature_norm=77.06\n",
      "Iter 32  time=0.03  loss=6213.49  active=5877  feature_norm=77.42\n",
      "Iter 33  time=0.03  loss=6192.53  active=5869  feature_norm=78.02\n",
      "Iter 34  time=0.04  loss=6165.43  active=5849  feature_norm=78.96\n",
      "Iter 35  time=0.08  loss=6150.98  active=5839  feature_norm=80.30\n",
      "Iter 36  time=0.03  loss=6124.61  active=5829  feature_norm=80.76\n",
      "Iter 37  time=0.03  loss=6109.84  active=5816  feature_norm=81.38\n",
      "Iter 38  time=0.03  loss=6095.79  active=5793  feature_norm=81.96\n",
      "Iter 39  time=0.04  loss=6084.09  active=5729  feature_norm=82.04\n",
      "Iter 40  time=0.04  loss=6073.30  active=5702  feature_norm=82.24\n",
      "Iter 41  time=0.04  loss=6064.27  active=5700  feature_norm=82.10\n",
      "Iter 42  time=0.04  loss=6055.38  active=5679  feature_norm=82.10\n",
      "Iter 43  time=0.03  loss=6044.94  active=5615  feature_norm=82.47\n",
      "Iter 44  time=0.03  loss=6037.55  active=5599  feature_norm=82.73\n",
      "Iter 45  time=0.03  loss=6032.66  active=5594  feature_norm=82.84\n",
      "Iter 46  time=0.02  loss=6027.14  active=5586  feature_norm=82.99\n",
      "Iter 47  time=0.03  loss=6024.81  active=5560  feature_norm=83.21\n",
      "Iter 48  time=0.03  loss=6019.00  active=5572  feature_norm=83.28\n",
      "Iter 49  time=0.03  loss=6017.10  active=5558  feature_norm=83.31\n",
      "Iter 50  time=0.03  loss=6011.94  active=5537  feature_norm=83.40\n",
      "Iter 51  time=0.03  loss=6011.92  active=5509  feature_norm=83.46\n",
      "Iter 52  time=0.03  loss=6006.96  active=5519  feature_norm=83.49\n",
      "Iter 53  time=0.03  loss=6005.42  active=5520  feature_norm=83.50\n",
      "Iter 54  time=0.04  loss=6002.71  active=5497  feature_norm=83.52\n",
      "Iter 55  time=0.04  loss=6000.37  active=5490  feature_norm=83.53\n",
      "Iter 56  time=0.04  loss=5998.00  active=5480  feature_norm=83.57\n",
      "Iter 57  time=0.04  loss=5995.96  active=5480  feature_norm=83.58\n",
      "Iter 58  time=0.04  loss=5993.90  active=5460  feature_norm=83.62\n",
      "Iter 59  time=0.07  loss=5991.93  active=5451  feature_norm=83.61\n",
      "Iter 60  time=0.04  loss=5989.94  active=5447  feature_norm=83.62\n",
      "Iter 61  time=0.04  loss=5988.36  active=5442  feature_norm=83.60\n",
      "Iter 62  time=0.04  loss=5986.60  active=5434  feature_norm=83.64\n",
      "Iter 63  time=0.04  loss=5985.39  active=5431  feature_norm=83.62\n",
      "Iter 64  time=0.04  loss=5984.18  active=5420  feature_norm=83.65\n",
      "Iter 65  time=0.04  loss=5983.01  active=5423  feature_norm=83.65\n",
      "Iter 66  time=0.03  loss=5981.92  active=5424  feature_norm=83.66\n",
      "Iter 67  time=0.06  loss=5981.26  active=5406  feature_norm=83.66\n",
      "Iter 68  time=0.04  loss=5979.95  active=5403  feature_norm=83.67\n",
      "Iter 69  time=0.04  loss=5979.03  active=5394  feature_norm=83.67\n",
      "Iter 70  time=0.04  loss=5978.14  active=5389  feature_norm=83.67\n",
      "Iter 71  time=0.04  loss=5977.45  active=5384  feature_norm=83.67\n",
      "Iter 72  time=0.09  loss=5976.55  active=5382  feature_norm=83.68\n",
      "Iter 73  time=0.07  loss=5975.85  active=5378  feature_norm=83.68\n",
      "Iter 74  time=0.05  loss=5975.13  active=5371  feature_norm=83.69\n",
      "Iter 75  time=0.10  loss=5974.50  active=5365  feature_norm=83.69\n",
      "Iter 76  time=0.03  loss=5973.76  active=5360  feature_norm=83.71\n",
      "Iter 77  time=0.03  loss=5973.10  active=5355  feature_norm=83.71\n",
      "Iter 78  time=0.03  loss=5972.48  active=5354  feature_norm=83.73\n",
      "Iter 79  time=0.04  loss=5971.78  active=5353  feature_norm=83.74\n",
      "Iter 80  time=0.03  loss=5971.32  active=5350  feature_norm=83.75\n",
      "Iter 81  time=0.05  loss=5970.78  active=5354  feature_norm=83.76\n",
      "Iter 82  time=0.03  loss=5970.36  active=5351  feature_norm=83.78\n",
      "Iter 83  time=0.03  loss=5969.89  active=5352  feature_norm=83.78\n",
      "Iter 84  time=0.03  loss=5969.51  active=5344  feature_norm=83.80\n",
      "Iter 85  time=0.03  loss=5969.12  active=5345  feature_norm=83.80\n",
      "Iter 86  time=0.03  loss=5968.73  active=5348  feature_norm=83.82\n",
      "Iter 87  time=0.03  loss=5968.32  active=5347  feature_norm=83.81\n",
      "Iter 88  time=0.03  loss=5968.02  active=5339  feature_norm=83.83\n",
      "Iter 89  time=0.03  loss=5967.60  active=5341  feature_norm=83.83\n",
      "Iter 90  time=0.03  loss=5967.36  active=5337  feature_norm=83.84\n",
      "Iter 91  time=0.03  loss=5966.90  active=5339  feature_norm=83.84\n",
      "Iter 92  time=0.03  loss=5966.67  active=5336  feature_norm=83.86\n",
      "Iter 93  time=0.05  loss=5966.27  active=5337  feature_norm=83.85\n",
      "Iter 94  time=0.03  loss=5966.01  active=5338  feature_norm=83.86\n",
      "Iter 95  time=0.03  loss=5965.61  active=5338  feature_norm=83.86\n",
      "Iter 96  time=0.04  loss=5965.39  active=5333  feature_norm=83.87\n",
      "Iter 97  time=0.03  loss=5965.00  active=5335  feature_norm=83.86\n",
      "Iter 98  time=0.03  loss=5964.80  active=5330  feature_norm=83.88\n",
      "Iter 99  time=0.03  loss=5964.44  active=5330  feature_norm=83.87\n",
      "Iter 100 time=0.04  loss=5964.24  active=5329  feature_norm=83.89\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 3.568\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 5329 (6894)\n",
      "Number of active attributes: 3756 (4990)\n",
      "Number of active labels: 9 (9)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crf.fit(X_train, y_train) #instead of downgrading sklearn for mitigating this issue, gave a try-catch block\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "089e72a4-2244-4b00-96be-bf2c4bdb87ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "print(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "793ab2e5-60b8-4ea4-8db5-423a9ef1c521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0077b636-0aca-4148-bc48-e37ac6ed7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import metrics as crf_metrics\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') #Intentionally removing 'O' to understand how well the model classifies other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "964345a0-f5cc-47a3-a594-ab6e52f3ac67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.823409066315601"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn_crfsuite import metrics\n",
    "metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08df401-913d-4d37-8053-0dc72d261ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
