{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cfe78e4-87f5-4a49-b56d-1c55fe7cf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This example is based on SQuAD dataset. (Stanford Question Answering Dataset)\n",
    "#Depending on the model and the GPU (if using), the batch size is adjusted to avoid out-of-memory errors. \n",
    "#The three parameters below must be set for the notebook to run smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b1f677-9038-4492-9b45-a72b4e1a9e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_v2 = False #specifying version of the dataset\n",
    "model_checkpoint = \"distilbert-base-uncased\" #\n",
    "batch_size = 16 #defining the batch size accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f526076f-7166-45a6-acdf-cad70b1a6f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.41.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f2f899-9e52-4184-a288-48580baf778f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "datasets = load_dataset(\"squad_v2\" if squad_v2 else \"squad\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c8ae6e6-b539-4cdd-821d-0338dc8ba0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c5cfa7-8038-47be-8e83-ced1c31b8844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9ecff01-117d-4f89-a7d5-7c640d549b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) #run by Rust, much more faster implementation i.e., fast tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6af41fa-e2e9-4528-867f-4c4682a3b9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2054, 2003, 2115, 2171, 1029, 102, 2026, 2171, 2003, 25353, 22144, 2378, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"What is your name?\", \"My name is Kamalam.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eadf4ace-92c7-4a68-ad9c-53794ab3237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384 # The maximum length of a feature (question and context)\n",
    "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "071dd74a-a170-4d55-82f5-dd2f0db8fb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, example in enumerate(datasets[\"train\"]):\n",
    "    if len(tokenizer(example[\"question\"], example[\"context\"])[\"input_ids\"]) > 384:\n",
    "        break\n",
    "example = datasets[\"train\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b516129f-4901-4275-b185-99d01021faf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733caf74776f4190066124c',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': \"The men's basketball team has over 1,600 wins, one of only 12 schools who have reached that mark, and have appeared in 28 NCAA tournaments. Former player Austin Carr holds the record for most points scored in a single game of the tournament with 61. Although the team has never won the NCAA Tournament, they were named by the Helms Athletic Foundation as national champions twice. The team has orchestrated a number of upsets of number one ranked teams, the most notable of which was ending UCLA's record 88-game winning streak in 1974. The team has beaten an additional eight number-one teams, and those nine wins rank second, to UCLA's 10, all-time in wins against the top team. The team plays in newly renovated Purcell Pavilion (within the Edmund P. Joyce Center), which reopened for the beginning of the 2009–2010 season. The team is coached by Mike Brey, who, as of the 2014–15 season, his fifteenth at Notre Dame, has achieved a 332-165 record. In 2009 they were invited to the NIT, where they advanced to the semifinals but were beaten by Penn State who went on and beat Baylor in the championship. The 2010–11 team concluded its regular season ranked number seven in the country, with a record of 25–5, Brey's fifth straight 20-win season, and a second-place finish in the Big East. During the 2014-15 season, the team went 32-6 and won the ACC conference tournament, later advancing to the Elite 8, where the Fighting Irish lost on a missed buzzer-beater against then undefeated Kentucky. Led by NBA draft picks Jerian Grant and Pat Connaughton, the Fighting Irish beat the eventual national champion Duke Blue Devils twice during the season. The 32 wins were the most by the Fighting Irish team since 1908-09.\",\n",
       " 'question': \"How many wins does the Notre Dame men's basketball team have?\",\n",
       " 'answers': {'text': ['over 1,600'], 'answer_start': [30]}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example #max_length context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69c625b2-8e4d-416c-8f38-c73acdb62b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] this sentence is not [SEP]\n",
      "[CLS] is not too long [SEP]\n",
      "[CLS] too long but we [SEP]\n",
      "[CLS] but we are going [SEP]\n",
      "[CLS] are going to split [SEP]\n",
      "[CLS] to split it anyway [SEP]\n",
      "[CLS] it anyway. [SEP]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This sentence is not too long but we are going to split it anyway.\"\n",
    "inputs = tokenizer(\n",
    "    sentence, truncation=True, return_overflowing_tokens=True, max_length=6, stride=2\n",
    ")\n",
    "\n",
    "for ids in inputs[\"input_ids\"]:\n",
    "    print(tokenizer.decode(ids)) #[CLS] beginning of a sentence/chunk/split #[SEP] separator tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49cb14ca-6b22-43d6-b75d-2dfee0623f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length, #max length for context\n",
    "    truncation=\"only_second\", #truncate only the context\n",
    "    return_overflowing_tokens=True, #overlapping token chunks ensures our answer doesn't get missed\n",
    "    stride=doc_stride #stride window over the text for chunking\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfa25854-e33e-48dd-9dd2-d6f1933b67c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] how many wins does the notre dame men's basketball team have? [SEP] the men's basketball team has over 1, 600 wins, one of only 12 schools who have reached that mark, and have appeared in 28 ncaa tournaments. former player austin carr holds the record for most points scored in a single game of the tournament with 61. although the team has never won the ncaa tournament, they were named by the helms athletic foundation as national champions twice. the team has orchestrated a number of upsets of number one ranked teams, the most notable of which was ending ucla's record 88 - game winning streak in 1974. the team has beaten an additional eight number - one teams, and those nine wins rank second, to ucla's 10, all - time in wins against the top team. the team plays in newly renovated purcell pavilion ( within the edmund p. joyce center ), which reopened for the beginning of the 2009 – 2010 season. the team is coached by mike brey, who, as of the 2014 – 15 season, his fifteenth at notre dame, has achieved a 332 - 165 record. in 2009 they were invited to the nit, where they advanced to the semifinals but were beaten by penn state who went on and beat baylor in the championship. the 2010 – 11 team concluded its regular season ranked number seven in the country, with a record of 25 – 5, brey's fifth straight 20 - win season, and a second - place finish in the big east. during the 2014 - 15 season, the team went 32 - 6 and won the acc conference tournament, later advancing to the elite 8, where the fighting irish lost on a missed buzzer - beater against then undefeated kentucky. led by nba draft picks jerian grant and pat connaughton, the fighting irish beat the eventual national champion duke blue devils twice during the season. the 32 wins were [SEP]\n",
      "\n",
      "\n",
      "[CLS] how many wins does the notre dame men's basketball team have? [SEP] championship. the 2010 – 11 team concluded its regular season ranked number seven in the country, with a record of 25 – 5, brey's fifth straight 20 - win season, and a second - place finish in the big east. during the 2014 - 15 season, the team went 32 - 6 and won the acc conference tournament, later advancing to the elite 8, where the fighting irish lost on a missed buzzer - beater against then undefeated kentucky. led by nba draft picks jerian grant and pat connaughton, the fighting irish beat the eventual national champion duke blue devils twice during the season. the 32 wins were the most by the fighting irish team since 1908 - 09. [SEP]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_example[\"input_ids\"][:2]:\n",
    "    print(tokenizer.decode(x)) #decodes the mapping to give text\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a709c32f-44b5-495f-ba19-89effc53f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "tokenized_example = tokenizer(\n",
    "    example[\"question\"],\n",
    "    example[\"context\"],\n",
    "    max_length=max_length,\n",
    "    truncation=\"only_second\", \n",
    "    return_overflowing_tokens=True,\n",
    "    return_offsets_mapping=True, #returns the mapping between tokens and position in the og context, the offset of the particular token is returned. (0,0) is for [CLS]\n",
    "    stride=doc_stride\n",
    ")\n",
    "print(tokenized_example[\"offset_mapping\"][0][1]) #the offset mapping for \"how\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbd20fd6-cbc9-421c-87a0-5b3dd8f5f9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how How\n"
     ]
    }
   ],
   "source": [
    "first_token_id = tokenized_example[\"input_ids\"][0][1]\n",
    "offsets = tokenized_example[\"offset_mapping\"][0][1]\n",
    "print(tokenizer.convert_ids_to_tokens([first_token_id])[0], example[\"question\"][offsets[0]:offsets[1]]) #mapping between ids to offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a13b1948-7ab6-45a6-936d-fc3318ed5c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example[\"offset_mapping\"][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cbfae4d-cad8-4573-ae10-cf6b8ced8ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "how\n",
      "many\n",
      "wins\n",
      "does\n",
      "the\n",
      "notre\n",
      "dame\n",
      "men\n",
      "'\n",
      "s\n",
      "basketball\n",
      "team\n",
      "have\n",
      "?\n",
      "[SEP]\n",
      "the\n",
      "men\n",
      "'\n",
      "s\n",
      "basketball\n",
      "team\n",
      "has\n",
      "over\n",
      "1\n",
      ",\n",
      "600\n",
      "wins\n",
      ",\n",
      "one\n",
      "of\n",
      "only\n",
      "12\n",
      "schools\n",
      "who\n",
      "have\n",
      "reached\n",
      "that\n",
      "mark\n",
      ",\n",
      "and\n",
      "have\n",
      "appeared\n",
      "in\n",
      "28\n",
      "ncaa\n",
      "tournaments\n",
      ".\n",
      "former\n",
      "player\n",
      "austin\n",
      "carr\n",
      "holds\n",
      "the\n",
      "record\n",
      "for\n",
      "most\n",
      "points\n",
      "scored\n",
      "in\n",
      "a\n",
      "single\n",
      "game\n",
      "of\n",
      "the\n",
      "tournament\n",
      "with\n",
      "61\n",
      ".\n",
      "although\n",
      "the\n",
      "team\n",
      "has\n",
      "never\n",
      "won\n",
      "the\n",
      "ncaa\n",
      "tournament\n",
      ",\n",
      "they\n",
      "were\n",
      "named\n",
      "by\n",
      "the\n",
      "helm\n",
      "##s\n",
      "athletic\n",
      "foundation\n",
      "as\n",
      "national\n",
      "champions\n",
      "twice\n",
      ".\n",
      "the\n",
      "team\n",
      "has\n",
      "orchestrated\n",
      "a\n",
      "number\n",
      "of\n",
      "upset\n",
      "##s\n",
      "of\n",
      "number\n",
      "one\n",
      "ranked\n",
      "teams\n",
      ",\n",
      "the\n",
      "most\n",
      "notable\n",
      "of\n",
      "which\n",
      "was\n",
      "ending\n",
      "ucla\n",
      "'\n",
      "s\n",
      "record\n",
      "88\n",
      "-\n",
      "game\n",
      "winning\n",
      "streak\n",
      "in\n",
      "1974\n",
      ".\n",
      "the\n",
      "team\n",
      "has\n",
      "beaten\n",
      "an\n",
      "additional\n",
      "eight\n",
      "number\n",
      "-\n",
      "one\n",
      "teams\n",
      ",\n",
      "and\n",
      "those\n",
      "nine\n",
      "wins\n",
      "rank\n",
      "second\n",
      ",\n",
      "to\n",
      "ucla\n",
      "'\n",
      "s\n",
      "10\n",
      ",\n",
      "all\n",
      "-\n",
      "time\n",
      "in\n",
      "wins\n",
      "against\n",
      "the\n",
      "top\n",
      "team\n",
      ".\n",
      "the\n",
      "team\n",
      "plays\n",
      "in\n",
      "newly\n",
      "renovated\n",
      "purcell\n",
      "pavilion\n",
      "(\n",
      "within\n",
      "the\n",
      "edmund\n",
      "p\n",
      ".\n",
      "joyce\n",
      "center\n",
      ")\n",
      ",\n",
      "which\n",
      "reopened\n",
      "for\n",
      "the\n",
      "beginning\n",
      "of\n",
      "the\n",
      "2009\n",
      "–\n",
      "2010\n",
      "season\n",
      ".\n",
      "the\n",
      "team\n",
      "is\n",
      "coached\n",
      "by\n",
      "mike\n",
      "br\n",
      "##ey\n",
      ",\n",
      "who\n",
      ",\n",
      "as\n",
      "of\n",
      "the\n",
      "2014\n",
      "–\n",
      "15\n",
      "season\n",
      ",\n",
      "his\n",
      "fifteenth\n",
      "at\n",
      "notre\n",
      "dame\n",
      ",\n",
      "has\n",
      "achieved\n",
      "a\n",
      "332\n",
      "-\n",
      "165\n",
      "record\n",
      ".\n",
      "in\n",
      "2009\n",
      "they\n",
      "were\n",
      "invited\n",
      "to\n",
      "the\n",
      "ni\n",
      "##t\n",
      ",\n",
      "where\n",
      "they\n",
      "advanced\n",
      "to\n",
      "the\n",
      "semifinals\n",
      "but\n",
      "were\n",
      "beaten\n",
      "by\n",
      "penn\n",
      "state\n",
      "who\n",
      "went\n",
      "on\n",
      "and\n",
      "beat\n",
      "baylor\n",
      "in\n",
      "the\n",
      "championship\n",
      ".\n",
      "the\n",
      "2010\n",
      "–\n",
      "11\n",
      "team\n",
      "concluded\n",
      "its\n",
      "regular\n",
      "season\n",
      "ranked\n",
      "number\n",
      "seven\n",
      "in\n",
      "the\n",
      "country\n",
      ",\n",
      "with\n",
      "a\n",
      "record\n",
      "of\n",
      "25\n",
      "–\n",
      "5\n",
      ",\n",
      "br\n",
      "##ey\n",
      "'\n",
      "s\n",
      "fifth\n",
      "straight\n",
      "20\n",
      "-\n",
      "win\n",
      "season\n",
      ",\n",
      "and\n",
      "a\n",
      "second\n",
      "-\n",
      "place\n",
      "finish\n",
      "in\n",
      "the\n",
      "big\n",
      "east\n",
      ".\n",
      "during\n",
      "the\n",
      "2014\n",
      "-\n",
      "15\n",
      "season\n",
      ",\n",
      "the\n",
      "team\n",
      "went\n",
      "32\n",
      "-\n",
      "6\n",
      "and\n",
      "won\n",
      "the\n",
      "acc\n",
      "conference\n",
      "tournament\n",
      ",\n",
      "later\n",
      "advancing\n",
      "to\n",
      "the\n",
      "elite\n",
      "8\n",
      ",\n",
      "where\n",
      "the\n",
      "fighting\n",
      "irish\n",
      "lost\n",
      "on\n",
      "a\n",
      "missed\n",
      "buzz\n",
      "##er\n",
      "-\n",
      "beat\n",
      "##er\n",
      "against\n",
      "then\n",
      "undefeated\n",
      "kentucky\n",
      ".\n",
      "led\n",
      "by\n",
      "nba\n",
      "draft\n",
      "picks\n",
      "je\n",
      "##rian\n",
      "grant\n",
      "and\n",
      "pat\n",
      "con\n",
      "##na\n",
      "##ught\n",
      "##on\n",
      ",\n",
      "the\n",
      "fighting\n",
      "irish\n",
      "beat\n",
      "the\n",
      "eventual\n",
      "national\n",
      "champion\n",
      "duke\n",
      "blue\n",
      "devils\n",
      "twice\n",
      "during\n",
      "the\n",
      "season\n",
      ".\n",
      "the\n",
      "32\n",
      "wins\n",
      "were\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "for x in tokenized_example[\"input_ids\"][0]:\n",
    "    print(tokenizer.decode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1065b85-7545-4105-97d6-d95839ad5355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, None, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, None]\n"
     ]
    }
   ],
   "source": [
    "sequence_ids = tokenized_example.sequence_ids()\n",
    "print(sequence_ids) #0 indicates question #1 indicates context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93ba1efe-0377-46e9-9939-12e0c0a75acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To find start and end tokens for our answer based on the context, sequence_ids along with context can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12bc8a7b-c567-4a61-a2b0-291d8238be05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2129,\n",
       " 2116,\n",
       " 5222,\n",
       " 2515,\n",
       " 1996,\n",
       " 10289,\n",
       " 8214,\n",
       " 2273,\n",
       " 1005,\n",
       " 1055,\n",
       " 3455,\n",
       " 2136,\n",
       " 2031,\n",
       " 1029,\n",
       " 102,\n",
       " 1996,\n",
       " 2273,\n",
       " 1005,\n",
       " 1055,\n",
       " 3455,\n",
       " 2136,\n",
       " 2038,\n",
       " 2058,\n",
       " 1015,\n",
       " 1010,\n",
       " 5174,\n",
       " 5222,\n",
       " 1010,\n",
       " 2028,\n",
       " 1997,\n",
       " 2069,\n",
       " 2260,\n",
       " 2816,\n",
       " 2040,\n",
       " 2031,\n",
       " 2584,\n",
       " 2008,\n",
       " 2928,\n",
       " 1010,\n",
       " 1998,\n",
       " 2031,\n",
       " 2596,\n",
       " 1999,\n",
       " 2654,\n",
       " 5803,\n",
       " 8504,\n",
       " 1012,\n",
       " 2280,\n",
       " 2447,\n",
       " 5899,\n",
       " 12385,\n",
       " 4324,\n",
       " 1996,\n",
       " 2501,\n",
       " 2005,\n",
       " 2087,\n",
       " 2685,\n",
       " 3195,\n",
       " 1999,\n",
       " 1037,\n",
       " 2309,\n",
       " 2208,\n",
       " 1997,\n",
       " 1996,\n",
       " 2977,\n",
       " 2007,\n",
       " 6079,\n",
       " 1012,\n",
       " 2348,\n",
       " 1996,\n",
       " 2136,\n",
       " 2038,\n",
       " 2196,\n",
       " 2180,\n",
       " 1996,\n",
       " 5803,\n",
       " 2977,\n",
       " 1010,\n",
       " 2027,\n",
       " 2020,\n",
       " 2315,\n",
       " 2011,\n",
       " 1996,\n",
       " 16254,\n",
       " 2015,\n",
       " 5188,\n",
       " 3192,\n",
       " 2004,\n",
       " 2120,\n",
       " 3966,\n",
       " 3807,\n",
       " 1012,\n",
       " 1996,\n",
       " 2136,\n",
       " 2038,\n",
       " 23339,\n",
       " 1037,\n",
       " 2193,\n",
       " 1997,\n",
       " 6314,\n",
       " 2015,\n",
       " 1997,\n",
       " 2193,\n",
       " 2028,\n",
       " 4396,\n",
       " 2780,\n",
       " 1010,\n",
       " 1996,\n",
       " 2087,\n",
       " 3862,\n",
       " 1997,\n",
       " 2029,\n",
       " 2001,\n",
       " 4566,\n",
       " 12389,\n",
       " 1005,\n",
       " 1055,\n",
       " 2501,\n",
       " 6070,\n",
       " 1011,\n",
       " 2208,\n",
       " 3045,\n",
       " 9039,\n",
       " 1999,\n",
       " 3326,\n",
       " 1012,\n",
       " 1996,\n",
       " 2136,\n",
       " 2038,\n",
       " 7854,\n",
       " 2019,\n",
       " 3176,\n",
       " 2809,\n",
       " 2193,\n",
       " 1011,\n",
       " 2028,\n",
       " 2780,\n",
       " 1010,\n",
       " 1998,\n",
       " 2216,\n",
       " 3157,\n",
       " 5222,\n",
       " 4635,\n",
       " 2117,\n",
       " 1010,\n",
       " 2000,\n",
       " 12389,\n",
       " 1005,\n",
       " 1055,\n",
       " 2184,\n",
       " 1010,\n",
       " 2035,\n",
       " 1011,\n",
       " 2051,\n",
       " 1999,\n",
       " 5222,\n",
       " 2114,\n",
       " 1996,\n",
       " 2327,\n",
       " 2136,\n",
       " 1012,\n",
       " 1996,\n",
       " 2136,\n",
       " 3248,\n",
       " 1999,\n",
       " 4397,\n",
       " 10601,\n",
       " 26429,\n",
       " 10531,\n",
       " 1006,\n",
       " 2306,\n",
       " 1996,\n",
       " 9493,\n",
       " 1052,\n",
       " 1012,\n",
       " 11830,\n",
       " 2415,\n",
       " 1007,\n",
       " 1010,\n",
       " 2029,\n",
       " 11882,\n",
       " 2005,\n",
       " 1996,\n",
       " 2927,\n",
       " 1997,\n",
       " 1996,\n",
       " 2268,\n",
       " 1516,\n",
       " 2230,\n",
       " 2161,\n",
       " 1012,\n",
       " 1996,\n",
       " 2136,\n",
       " 2003,\n",
       " 8868,\n",
       " 2011,\n",
       " 3505,\n",
       " 7987,\n",
       " 3240,\n",
       " 1010,\n",
       " 2040,\n",
       " 1010,\n",
       " 2004,\n",
       " 1997,\n",
       " 1996,\n",
       " 2297,\n",
       " 1516,\n",
       " 2321,\n",
       " 2161,\n",
       " 1010,\n",
       " 2010,\n",
       " 16249,\n",
       " 2012,\n",
       " 10289,\n",
       " 8214,\n",
       " 1010,\n",
       " 2038,\n",
       " 4719,\n",
       " 1037,\n",
       " 29327,\n",
       " 1011,\n",
       " 13913,\n",
       " 2501,\n",
       " 1012,\n",
       " 1999,\n",
       " 2268,\n",
       " 2027,\n",
       " 2020,\n",
       " 4778,\n",
       " 2000,\n",
       " 1996,\n",
       " 9152,\n",
       " 2102,\n",
       " 1010,\n",
       " 2073,\n",
       " 2027,\n",
       " 3935,\n",
       " 2000,\n",
       " 1996,\n",
       " 8565,\n",
       " 2021,\n",
       " 2020,\n",
       " 7854,\n",
       " 2011,\n",
       " 9502,\n",
       " 2110,\n",
       " 2040,\n",
       " 2253,\n",
       " 2006,\n",
       " 1998,\n",
       " 3786,\n",
       " 23950,\n",
       " 1999,\n",
       " 1996,\n",
       " 2528,\n",
       " 1012,\n",
       " 1996,\n",
       " 2230,\n",
       " 1516,\n",
       " 2340,\n",
       " 2136,\n",
       " 5531,\n",
       " 2049,\n",
       " 3180,\n",
       " 2161,\n",
       " 4396,\n",
       " 2193,\n",
       " 2698,\n",
       " 1999,\n",
       " 1996,\n",
       " 2406,\n",
       " 1010,\n",
       " 2007,\n",
       " 1037,\n",
       " 2501,\n",
       " 1997,\n",
       " 2423,\n",
       " 1516,\n",
       " 1019,\n",
       " 1010,\n",
       " 7987,\n",
       " 3240,\n",
       " 1005,\n",
       " 1055,\n",
       " 3587,\n",
       " 3442,\n",
       " 2322,\n",
       " 1011,\n",
       " 2663,\n",
       " 2161,\n",
       " 1010,\n",
       " 1998,\n",
       " 1037,\n",
       " 2117,\n",
       " 1011,\n",
       " 2173,\n",
       " 3926,\n",
       " 1999,\n",
       " 1996,\n",
       " 2502,\n",
       " 2264,\n",
       " 1012,\n",
       " 2076,\n",
       " 1996,\n",
       " 2297,\n",
       " 1011,\n",
       " 2321,\n",
       " 2161,\n",
       " 1010,\n",
       " 1996,\n",
       " 2136,\n",
       " 2253,\n",
       " 3590,\n",
       " 1011,\n",
       " 1020,\n",
       " 1998,\n",
       " 2180,\n",
       " 1996,\n",
       " 16222,\n",
       " 3034,\n",
       " 2977,\n",
       " 1010,\n",
       " 2101,\n",
       " 10787,\n",
       " 2000,\n",
       " 1996,\n",
       " 7069,\n",
       " 1022,\n",
       " 1010,\n",
       " 2073,\n",
       " 1996,\n",
       " 3554,\n",
       " 3493,\n",
       " 2439,\n",
       " 2006,\n",
       " 1037,\n",
       " 4771,\n",
       " 12610,\n",
       " 2121,\n",
       " 1011,\n",
       " 3786,\n",
       " 2121,\n",
       " 2114,\n",
       " 2059,\n",
       " 15188,\n",
       " 5612,\n",
       " 1012,\n",
       " 2419,\n",
       " 2011,\n",
       " 6452,\n",
       " 4433,\n",
       " 11214,\n",
       " 15333,\n",
       " 6862,\n",
       " 3946,\n",
       " 1998,\n",
       " 6986,\n",
       " 9530,\n",
       " 2532,\n",
       " 18533,\n",
       " 2239,\n",
       " 1010,\n",
       " 1996,\n",
       " 3554,\n",
       " 3493,\n",
       " 3786,\n",
       " 1996,\n",
       " 9523,\n",
       " 2120,\n",
       " 3410,\n",
       " 3804,\n",
       " 2630,\n",
       " 13664,\n",
       " 3807,\n",
       " 2076,\n",
       " 1996,\n",
       " 2161,\n",
       " 1012,\n",
       " 1996,\n",
       " 3590,\n",
       " 5222,\n",
       " 2020,\n",
       " 102]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_example[\"input_ids\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57cb0de4-e36f-4fe4-82ed-0ab22edc49c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 26\n"
     ]
    }
   ],
   "source": [
    "answers = example[\"answers\"]\n",
    "start_char = answers[\"answer_start\"][0]\n",
    "end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "#Start token index of the current span in the text.\n",
    "token_start_index = 0\n",
    "while sequence_ids[token_start_index] != 1:\n",
    "    token_start_index += 1\n",
    "\n",
    "#End token index of the current span in the text.\n",
    "token_end_index = len(tokenized_example[\"input_ids\"][0]) - 1\n",
    "while sequence_ids[token_end_index] != 1:\n",
    "    token_end_index -= 1\n",
    "\n",
    "#Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
    "offsets = tokenized_example[\"offset_mapping\"][0]\n",
    "if (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "    # Move the token_start_index and token_end_index to the two ends of the answer.\n",
    "    while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "        token_start_index += 1\n",
    "    start_position = token_start_index - 1\n",
    "    while offsets[token_end_index][1] >= end_char:\n",
    "        token_end_index -= 1\n",
    "    end_position = token_end_index + 1\n",
    "    print(start_position, end_position)\n",
    "else:\n",
    "    print(\"The answer is not in this feature.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7871aec4-d68f-4d45-90b6-6686e6f7e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over 1, 600\n",
      "over 1,600\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_example[\"input_ids\"][0][start_position: end_position+1]))\n",
    "print(answers[\"text\"][0]) #the offset based value and the actual text value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feb2905a-fe65-47b8-b7db-a74a91f3ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\" \n",
    "#by default padding is on the right, bool value to check the same\n",
    "#to account for the special case where the model expects padding on the left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a1aa34f-83ba-46c3-8a3c-15c2b70b6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_features(examples):\n",
    "    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]] #removing whitespace at the beginning of a question.\n",
    "    \n",
    "    tokenized_examples = tokenizer(\n",
    "        examples[\"question\" if pad_on_right else \"context\"], \n",
    "        examples[\"context\" if pad_on_right else \"question\"],\n",
    "        truncation=\"only_second\" if pad_on_right else \"only_first\",\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    #Map from a feature to its corresponding example\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    #Map from token to character position in the original context.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        #Impossible answers are labelled with [CLS] token\n",
    "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
    "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
    "\n",
    "        #for that particular example, consider the sequence ids to separate the question and context\n",
    "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
    "\n",
    "        #One example can give several spans, this is the index of the example containing this span of text.\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = examples[\"answers\"][sample_index]\n",
    "        #If no answers are given, set the cls_index as answer.\n",
    "        if len(answers[\"answer_start\"]) == 0:\n",
    "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "        else:\n",
    "            #Start/end character index of the answer in the text.\n",
    "            start_char = answers[\"answer_start\"][0]\n",
    "            end_char = start_char + len(answers[\"text\"][0])\n",
    "\n",
    "            #Start token index of the current span in the text.\n",
    "            token_start_index = 0\n",
    "            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n",
    "                token_start_index += 1\n",
    "\n",
    "            #End token index of the current span in the text.\n",
    "            token_end_index = len(input_ids) - 1\n",
    "            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n",
    "                token_end_index -= 1\n",
    "\n",
    "            #Detect if the answer is out of the span (if so labeled with the CLS index).\n",
    "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
    "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
    "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
    "            else:\n",
    "                #Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
    "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
    "                    token_start_index += 1\n",
    "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
    "                while offsets[token_end_index][1] >= end_char:\n",
    "                    token_end_index -= 1\n",
    "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c955381-8fea-49f7-a03f-d87ccd569f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = prepare_train_features(datasets['train'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "934f6d50-c8ef-49a5-822f-a8d416ccb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names) #tokenising the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b237210-6960-4252-beff-83ec65e822f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ba61f4b-ae5c-498e-96cb-5bf0f0b7a851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up all the attributes to customize the training using \"TrainingArguments\"\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-squad\", #folder to save the model checkpoints\n",
    "    eval_strategy = \"epoch\", #evaluation strategy, done at the end of each epoch\n",
    "    learning_rate=2e-5, #defining the learning rate\n",
    "    per_device_train_batch_size=batch_size, #train size\n",
    "    per_device_eval_batch_size=batch_size, #batch size\n",
    "    num_train_epochs=3, #no.of epochs\n",
    "    weight_decay=0.01, #decay component\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "468559f3-01fe-4bba-b062-bcf0a4be2f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "data_collator = default_data_collator #to batch the processed examples together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c76da5d-43b3-4cd6-8a90-dfeeda0195b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#passing the configurations and dataset to the Trainer\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f4dedab-6852-4bfc-ac91-fd3b0c64290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='245' max='16599' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  245/16599 3:50:00 < 258:00:05, 0.02 it/s, Epoch 0.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1886\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1887\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1888\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1889\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1890\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\trainer.py:2216\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2213\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2222\u001b[0m ):\n\u001b[0;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\transformers\\trainer.py:3250\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3248\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\accelerate\\accelerator.py:2125\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2125\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\nlp\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7bd2f4-9605-4261-8b3c-c17769a67605",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"qa-bert-trained\") #Saving the model locally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
