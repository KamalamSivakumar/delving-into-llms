{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35958777-5849-415d-b39d-0934bb0e3c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83867aec-5413-4d88-9642-733b9ec058b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Attention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.comNoam Shazeer∗\\nGoogle Brain\\nnoam@google.comNiki Parmar∗\\nGoogle Research\\nnikip@google.comJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.comAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.eduŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention', metadata={'source': \"C:\\\\Users\\\\kamalam.s\\\\Desktop\\\\kamalam's\\\\nlp dev\\\\resources\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf\", 'page': 0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split documents in smaller chunks\n",
    "#Chunks of roughly 700 characters with an overlap of 50 characters\n",
    "loader = PyPDFLoader(\"C:\\\\Users\\\\kamalam.s\\\\Desktop\\\\kamalam's\\\\nlp dev\\\\resources\\\\NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
    "\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)\n",
    "\n",
    "docs_after_split[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc5f4243-4cf4-4d5d-bd7c-86c7b92c1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-l6-v2\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d567e5d-ba1b-4ae9-ac44-6b380bffa1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(docs_after_split, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b058780-cb46-452d-8bfb-a9780f90b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def retrieve_information(query, knowledge_base):\n",
    "    relevant_info = knowledge_base.similarity_search(query,k=3)\n",
    "    \n",
    "    context = []\n",
    "\n",
    "    for i in range(len((query, knowledge_base.similarity_search(query, search_kwargs={\"k\": 3}))[1])):\n",
    "        d = (query, knowledge_base.similarity_search(query, search_kwargs={\"k\": 3}))[1][i].dict()\n",
    "        context.append(d['page_content'])\n",
    "    \n",
    "    parsed_context = []\n",
    "    \n",
    "    for ele in context:\n",
    "        temp = re.sub(\"\\n\", '', ele)\n",
    "        temp = re.sub(r'www.\\S+', '', temp)\n",
    "        parsed_context.append(temp)\n",
    "    \n",
    "    final_context = \"\"\n",
    "    for ele in parsed_context:\n",
    "        final_context += ele\n",
    "    \n",
    "    return final_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e39ce63-41ef-4508-9b9f-4d26c609d205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence representations used by state-of-the-art models in machine translations, such as word-piece[31] and byte-pair [ 25] representations. To improve computational performance for tasks involvingvery long sequences, self-attention could be restricted to considering only a neighborhood of size rin6arXiv:1703.10722 , 2017.[19] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, BowenZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprintarXiv:1703.03130 , 2017.[20] Samy Bengio Łukasz Kaiser. Can active memory replace attention? In Advances in NeuralInformation Processing Systems, (NIPS) , 2016.10textual entailment and learning task-independent sentence representations [4, 22, 23, 19].End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-aligned recurrence and have been shown to perform well on simple-language question answering andlanguage modeling tasks [28].To the best of our knowledge, however, the Transformer is the ﬁrst transduction model relyingentirely on self-attention to compute representations of its input and output without using sequence-aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivateself-attention and discuss its advantages over models such as [14, 15] and [8].considerably, to O(k·n·d+n·d2). Even with k=n, however, the complexity of a separableconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,the approach we take in our model.As side beneﬁt, self-attention could yield more interpretable models. We inspect attention distributionsfrom our models and present and discuss examples in the appendix. Not only do individual attentionheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntacticand semantic structure of the sentences.5 TrainingThis section describes the training regime for our models.5.1 Training Data and Batching'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_information(\"attention\", vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7dbff4b-c56b-48ee-9a85-6e08db2530dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(query, knowledge_base):\n",
    "    # Retrieve relevant information based on the query\n",
    "    relevant_info = retrieve_information(query, knowledge_base)\n",
    "    # Model for text-generation, employing Q&A through text-generation, since debugging Q&A using llms and context info. (a work around basically)\n",
    "    text2text_generator = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=\"google-t5/t5-base\",\n",
    "    )\n",
    "    return text2text_generator(\"As a research information assistant, based on the paper provided, answer the question: \"+query+\" context: \"+relevant_info+ \"If you are not sure about the answer, say 'Unknown' and nothing else.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5345b625-5fbf-4cea-8483-b86fb25f3b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'each position in the encoder can attend to all positions in the input sequence'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"Explain positional encoding\", vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f57c48b2-0f03-49ae-8546-5680cd2ed735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'jointly attend to information from different representationsubspaces at different positions'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"what is multi-headed attention?\", vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "440a3ec0-2dbf-40c1-929a-d193c9c9bd62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Transformer'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"What is it about?\", vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb0b5015-e74f-4d0d-9126-ae61d4b63fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Unknown'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"What is RoBERTa?\", vectordb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
